---
title: "Boostcamp AI Tech (Day 007)"
date: 2024-08-13
layout: post
tags: [Naver Boostcamp, daily report]
---

[![Peer Session Badge](https://img.shields.io/badge/Peer%20Session-CC527A?style=flat)](../peer_session/day006.html)
RNN 모델에 대한 장단점, 기울기 소실 및 기울기 폭발 문제를 해결하는 방법, 그리고 LSTM과 Seq2Seq 모델
### RNN 모델의 장단점
**장점:**
- 시퀀스 데이터(예: 시계열, 텍스트) 처리에 적합합니다.
- 이전 입력에 대한 문맥을 유지할 수 있습니다.
- 입력과 출력의 길이가 가변적입니다.

**단점:**
- 긴 시퀀스에 대한 학습이 어려움.
- 기울기 소실(Vanishing Gradient) 및 기울기 폭발(Exploding Gradient) 문제에 취약합니다.
- 순차적으로 처리하므로 학습 속도가 느립니다.

### 기울기 소실 및 기울기 폭발 문제
- **기울기 소실:** 역전파 과정에서 기울기가 매우 작아져 가중치 업데이트가 거의 이루어지지 않는 문제입니다.
- **기울기 폭발:** 기울기가 너무 커져 가중치가 매우 큰 값으로 변하면서 모델이 불안정해지는 문제입니다.

**해결 방법:**
- **LSTM:** 게이트 구조를 통해 정보를 효과적으로 관리하여 긴 시퀀스의 의존성을 학습할 수 있습니다.
- **기울기 클리핑:** 기울기의 크기를 제한하여 기울기 폭발을 방지합니다.
- **배치 정규화:** 입력을 정규화하여 기울기 폭발 가능성을 줄입니다.

### LSTM과 Seq2Seq 모델
- **LSTM:** 긴 시퀀스의 장기 의존성을 학습할 수 있는 RNN의 변형입니다. 입력, 출력, 망각 게이트를 통해 정보를 효율적으로 조절합니다.
- **Seq2Seq:** 주로 기계 번역과 같은 작업에서 사용되는 모델 구조로, 인코더와 디코더로 구성되어 있습니다. 인코더는 입력 시퀀스를 컨텍스트 벡터로 변환하고, 디코더는 이를 바탕으로 출력 시퀀스를 생성합니다.

### PyTorch 기반 Seq2Seq 모델 코드
인코더는 입력 시퀀스를 받아 컨텍스트 벡터를 생성하고, 디코더는 이 벡터를 바탕으로 출력 시퀀스를 생성합니다. 학습 과정에서 "Teacher Forcing" 기법을 사용하여 학습 속도를 향상시킬 수 있습니다.
```python
import torch
import torch.nn as nn

class Encoder(nn.Module):
    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):
        super(Encoder, self).__init__()
        self.embedding = nn.Embedding(input_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, src):
        embedded = self.dropout(self.embedding(src))
        outputs, (hidden, cell) = self.rnn(embedded)
        return hidden, cell

class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout):
        super(Decoder, self).__init__()
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)
        self.fc_out = nn.Linear(hidden_dim, output_dim)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, input, hidden, cell):
        input = input.unsqueeze(0)
        embedded = self.dropout(self.embedding(input))
        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))
        prediction = self.fc_out(output.squeeze(0))
        return prediction, hidden, cell

class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder, device):
        super(Seq2Seq, self).__init__()
        self.encoder = encoder
        self.decoder = decoder
        self.device = device
    
    def forward(self, src, trg, teacher_forcing_ratio=0.5):
        hidden, cell = self.encoder(src)
        trg_len = trg.shape[0]
        trg_vocab_size = self.decoder.output_dim
        
        outputs = torch.zeros(trg_len, trg_vocab_size).to(self.device)
        input = trg[0, :]
        
        for t in range(1, trg_len):
            output, hidden, cell = self.decoder(input, hidden, cell)
            outputs[t] = output
            top1 = output.argmax(1)
            input = trg[t] if torch.rand(1).item() < teacher_forcing_ratio else top1
        
        return outputs
```
