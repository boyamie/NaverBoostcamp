---
title: "Boostcamp AI Tech (Day 022)"
date: 2024-09-03
layout: post
tags: [Naver Boostcamp, daily report]
---

# 1. 과제3
![](https://github.com/openai/CLIP/blob/main/CLIP.png?raw=true)

**CLIP**: supervised dataset을 이용하여 image-text pair에 대해 contrastive learning으로 학습하는 방법.
image encoder와 text encoder가 있다.
각 encoder에서 나온 feature들이 positive pair일 경우는 similarity가 커지도록, negative pair일 경우는 similarity가 작아지도록 학습된다.

pretrained CLIP을 이용하여 모델이 이미지의 어떤 부분을 참조하여 feature를 생성하고 있는지를 visualize하여 확인해보자!
Attention을 visualize하므로, image encoder는 ViT를 사용한다.

### Model Architectures
1. Bottle Neck 클래스
ResNet의 기본 블록인 Bottleneck은 Residual Learning을 위해 사용된다.
Residual 블록은 입력을 여러 레이어를 통해 변환한 출력에 입력을 더하는 구조를 가지고 있다.

2. AttentionPool2d 클래스
이미지를 인코딩한 후 Attention Pooling 레이어를 통해 각 패치의 중요도를 계산한다.
이미지 전체에 대한 맥락적 정보를 추출한다.

3. ModifiedResNet 클래스
이 클래스는 ResNet의 변형 버전으로, CLIP 모델의 이미지 인코더로 사용된다.
3개의 "stem" convolution을 사용하며, 각 레이어에서는 anti-aliasing을 위해 avgpool을 사용한다.

```python
class CustomBottleneck(nn.Module):
    expansion_factor = 4  # 확장 비율

    def __init__(self, input_channels, output_channels, stride=1):
        super(CustomBottleneck, self).__init__()
```
#### 1. **입력과 출력의 연결 (Residual Connection)**
- 네트워크의 핵심 아이디어는 입력을 여러 레이어를 거쳐 변형한 후, 변형된 출력에 입력을 더하는 것이다.
- 네트워크가 깊어지더라도 기울기 소실(vanishing gradient) 문제를 완화한다.

#### 2. **컨볼루션 연산**:
   - **Conv1**: 첫 번째 1x1 컨볼루션은 입력 채널의 수를 줄이거나 늘린다. 정보의 압축 및 확장.
   - **Conv2**: 두 번째 3x3 컨볼루션은 이미지의 공간 정보를 유지하면서 특징을 추출한다.
   - **Conv3**: 마지막 1x1 컨볼루션은 채널 수를 다시 확장하며, `expansion_factor`에 의해 확장된 채널 수를 만든다.

```python
        # 첫 번째 1x1 컨볼루션
        self.conv1 = nn.Conv2d(input_channels, output_channels, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(output_channels)
        self.relu = nn.ReLU(inplace=True)  # 모든 ReLU에 동일한 인스턴스를 사용

        # 두 번째 3x3 컨볼루션
        self.conv2 = nn.Conv2d(output_channels, output_channels, kernel_size=3, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(output_channels)

        # 필요 시 다운샘플링을 위한 평균 풀링 레이어
        self.avgpool = nn.AvgPool2d(stride) if stride > 1 else nn.Identity()

        # 마지막 1x1 컨볼루션
        self.conv3 = nn.Conv2d(output_channels, output_channels * self.expansion_factor, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(output_channels * self.expansion_factor)

        # 다운샘플링 레이어, 입력과 출력 크기가 다를 경우에만 사용
        self.downsample = None
        if stride > 1 or input_channels != output_channels * self.expansion_factor:
            self.downsample = nn.Sequential(OrderedDict([
                ("avgpool", nn.AvgPool2d(stride)),
                ("conv", nn.Conv2d(input_channels, output_channels * self.expansion_factor, kernel_size=1, bias=False)),
                ("bn", nn.BatchNorm2d(output_channels * self.expansion_factor))
            ]))
```
#### 3. **다운샘플링**:
   - 중간 레이어에서 스트라이드가 2 이상인 경우, 평균 풀링(`AvgPool2d`)을 사용하여 공간 크기를 절반으로 줄인다.
   - 입력과 출력의 크기가 다를 경우엔 별도의 다운샘플링 레이어가 추가되어 입력과 출력의 크기를 맞춘다.
```python
    def forward(self, x: torch.Tensor):
        # Identity 연결을 위한 입력 보존
        identity = x

        # 첫 번째 1x1 컨볼루션 및 활성화
        out = self.relu(self.bn1(self.conv1(x)))
        # 두 번째 3x3 컨볼루션 및 활성화
        out = self.relu(self.bn2(self.conv2(out)))
        # 필요 시 다운샘플링
        out = self.avgpool(out)
        # 마지막 1x1 컨볼루션 및 배치 정규화
        out = self.bn3(self.conv3(out))

        # 입력과 크기를 맞추기 위한 다운샘플링 처리
        if self.downsample is not None:
            identity = self.downsample(x)

        # 출력과 입력을 더해 Residual Connection
        out += identity
        # 최종 활성화
        out = self.relu(out)
        return out
```

#### 4. **배치 정규화 및 활성화 함수**:
   - 각 컨볼루션 뒤에는 배치 정규화(`BatchNorm2d`)가 위치하며, 이를 통해 각 배치의 통계적 변동을 줄여 안정적인 학습이 가능하다.
   - ReLU 활성화 함수는 비선형성을 부여하여 모델의 표현력을 증가시킨다.

#### 5. **Residual Connection의 장점**:
   - Residual Connection은 입력 데이터가 변형된 출력 데이터와 더해짐으로써, 모델이 학습 초기 단계에서도 유용한 특징을 유지할 수 있도록 도와준다.
   - 깊은 네트워크에서의 중요한 특징이다.
