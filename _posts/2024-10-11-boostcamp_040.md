---
title: "Boostcamp AI Tech (Day 040)"
date: 2024-10-11
layout: post
tags: [Naver Boostcamp, daily report]
---
[![Retrospectives Badge](https://img.shields.io/badge/Retrospectives-6A0DAD?style=flat)](../Retrospectives/week8.pdf)

## Describe the bug
- Wandb 용량 제약 100GB때문에 실험을 할 수 없는 현상 발생
- You need to set the save_best parameter in your CheckpointHook config. For example like this in case of an evaluation based on COCO mAP:

```python
default_hooks = dict(
    checkpoint=dict(
        type="CheckpointHook",
        save_best="coco/bbox_mAP",
        rule="greater"
    )
)
```
Take a look at the [CheckpointHook](https://mmengine.readthedocs.io/en/latest/tutorials/hook.html#checkpointhook) documentation to learn more about different configurations.

## To Reproduce
- Config 파일 수정: configs 파일에서 checkpoint_config 항목 수정
`cfg.checkpoint_config = dict(interval=1, save_best='bbox_mAP_50', save_last=True)`

- Wandb Artifacts로 모델 관리: Wandb의 Artifact 기능을 사용
```python
artifact = wandb.Artifact('best_model', type='model')
artifact.add_file('path_to_best_model.pth')
wandb.log_artifact(artifact)
```

## Expected behavior
```python
# 모델 훈련 시작 시 Wandb 초기화
wandb.init(
    project="Object Detection", 
    dir=experiment_dir,
    name=f'{model_name}_{random_code}',
    config=cfg._cfg_dict.to_dict()
)
```

# 모델 저장 및 Wandb 체크포인트 저장
```python
cfg.checkpoint_config = dict(interval=1, save_best='bbox_mAP_50', save_last=True)
```

# 훈련 후 Wandb Artifacts로 체크포인트 저장
```python
artifact = wandb.Artifact('best_model', type='model')
artifact.add_file(os.path.join(experiment_dir, 'best_model.pth'))
wandb.log_artifact(artifact)
```

## Screenshots
- ![스크린샷 2024-10-11 오전 10 46 14](https://github.com/user-attachments/assets/c5bdc697-6e1f-4900-8d6e-3a4055bd4a2b)


## Additional context
- MMDetection과 Wandb를 결합하여 최적의 모델만을 효율적으로 저장

## Possible Solution
- MMDetection과 Wandb를 결합하여 최적의 모델만을 효율적으로 저장

Inference
- https://github.com/open-mmlab/mmdetection/issues/10662 
