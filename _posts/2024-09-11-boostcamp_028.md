---
title: "Boostcamp AI Tech (Day 028)"
date: 2024-09-11
layout: post
tags: [Naver Boostcamp, daily report]
---

# 1. Progressive Resizing
모델이 처음부터 큰 해상도 이미지로 훈련하기가 어렵기때문에, 처음에는 작은 이미지부터 시작해서 점진적으로 크기를 키워가며 난이도를 높이는 방법이다.

#### 1.1 작게 시작: 낮은 해상도 이미지(64x64)로 시작한다. 
```python
initial_resolution = 64
```
모델이 합리적인 정확도에 도달하거나 Overfitting되기 시작할 때까지 훈련한다. 이렇게 하면 모델이 이미지의 일반적인 구조와 특징을 포착할 수 있다.

#### 1.2 크기 확대: Performance Metric을 기반으로 사전 정의된 체크포인트에서 이미지 크기를 점진적으로 증가시킨다(128x128). 이를 통해 모델이 점진적으로 세부 사항을 학습할 수 있다.
```python
final_resolution = 512
```
#### 3. 최종 Fine-Tuning: 최고 해상도(256x256)를 사용하여 마지막 훈련 단계에서 모델을 세부 특징에 대해 Fine-Tuning한다.
```python
for epoch in range(50):
    # Progressive Resizing을 통한 이미지 크기 증가
    if epoch % 10 == 0 and current_resolution < final_resolution:
        current_resolution *= 2
        print(f"이미지 해상도를 {current_resolution}x{current_resolution}로 증가합니다.")
        
        # 새롭게 해상도가 적용된 transform 설정
        train_transform = transforms.Compose([
            transforms.Resize((current_resolution, current_resolution)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),  # PIL 이미지를 텐서로 변환
        ])

        val_transform = transforms.Compose([
            transforms.Resize((current_resolution, current_resolution)),
            transforms.ToTensor(),  # PIL 이미지를 텐서로 변환
        ])

        # transform이 적용된 새로운 DataLoader 생성
        train_dataset = CustomDataset(root_dir=traindata_dir, info_df=train_df, transform=train_transform)
        val_dataset = CustomDataset(root_dir=traindata_dir, info_df=val_df, transform=val_transform)
        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

    model.train()
    running_loss = 0.0
    for batch in train_loader:
        inputs, targets = batch
        inputs, targets = inputs.to(device), targets.to(device)
        
        optimizer.zero_grad()
```
```shell
이미지 해상도를 128x128로 증가합니다.
Epoch 1, Train Loss: 4.519507782256349
Epoch 1, Validation Loss: 2.921922374278941
Confusion Matrix at epoch 1:
tensor([[0., 1., 0.,  ..., 0., 0., 0.],
        [0., 4., 0.,  ..., 0., 0., 0.],
        [0., 2., 4.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 2.],
        [0., 0., 0.,  ..., 0., 5., 0.],
        [0., 0., 0.,  ..., 0., 0., 3.]])
```
![image](https://github.com/user-attachments/assets/d4ef6c37-1d72-4e8c-982d-d9e089dcf062)

```
이미지 해상도를 256x256로 증가합니다.
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
/home/user/miniconda3/envs/seegen/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608883701/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
Epoch 11, Train Loss: 1.0485511052798717
Epoch 11, Validation Loss: 1.9003407752260248
Confusion Matrix at epoch 11:
tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 2.,  ..., 0., 0., 0.],
        [0., 0., 4.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 5., 0., 0.],
        [0., 0., 0.,  ..., 0., 6., 0.],
        [0., 0., 0.,  ..., 0., 0., 2.]])
```

![image](https://github.com/user-attachments/assets/307da392-0d90-4795-81a5-123e692b15d1)

